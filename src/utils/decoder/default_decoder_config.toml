# options: 'classification', 'regression'
task_type = ""
# Specify what GPU index to use. Write "cpu" to run on CPU. 
gpu_idx = 0

[network]
# Either "resnet152_decoder" or "resnet152_decoder_residual".
# resnet152_decoder will append several 1 layer module across different computation stages of the ResNet152.
# resnet152_decoder_residual will append more complex modules consisting of residual blocs, each containing two convolutional layers.
architecture_name = "resnet152_decoder"
# Whether to use the ResNet152 version pretrained with ImageNet.
imagenet_pretrained = true
# If you want to load a state_dict of a pretrained ResNet152 with decoders, specify the path here. If you use this, "imagenet_pretraing" will be ignored. 
state_dict_path = false
batch_size = 64


[training]
# This is just a name you want to give to this training session.If train_id == false, then run_id will be set equal to current datetime.
# Other key value pairs will be added in `run_info` by the train script.
train_id = false
learning_rate = 1e-5
weight_decay = 0
# If you want to continue training from a previous session, set this flag to the path of the optimizer (e.g. "models/decoder/id/checkpoint_optimizer.pt"). You also might want to change the network.load_state_dict above. Note that if you haven't saved the optimizer state, you can still continue training with a loaded model - it jut won't be as good at the beginning when you stopped training. 
optimizers_path = false
save_trained_model = true
# If the following is false, a model and optimizer will be only saved at the end of the training session, not at every epoch. Ignored if save_trained_model is false. 
save_at_epoch_end = true
# If True, it will evaluate the datasets specified as [[datasets.validation]] at some intervals during training. This will increase training time but could be useful for checking whether training is converging. 
evaluate_during_training = false

# Example of training datasets. Note that these are based on an annotation.csv file, created together with every dataset in MindSet. In the annotation file there is always a "Path" factor which contains the path of each image, and many factors. You need to specify which factor to use for classification in `label_cols`. 
# Note: for a classification task, we expect ALL datasets (training and validation) to have the same number of classes.
[training.dataset]
name = "dataset1"
annotation_file = "path/to/annotation/file.csv"
img_path_col_name = "Path"
# For a REGRESSION task: Use either a string indicating the factor to predict, or a list of string if you want to predict multiple factors. The number of output in the decoder will be automatically set to the number of factors to predict. 
# For a classification task, a string indicating the factor to use as a class label. The number of output in the decoder will be automatically set equal to the number of classes. 
label_cols = [""]
filters = {}      # { Type = "random" }

# Example of validation datasets.
# [[eval.datasets]]
# name = "name_val1"
# annotation_file = ""
# img_path_col_name = "Path"
# label_cols = ["val1"]
# filters = {} # or filters = { Type = "blabla"} 

# You can use more than one validation dataset
# [[eval.datasets]]
# name = "name_val2"
# annotation_file = ""
# img_path_col_name = "Path"
# label_cols = ["val2"]
# filters = {} # or filters = { Type = "blabla"} 


[training.stopping_conditions]
# Stop when this epoch/loss/accuracy. For loss and accuracy it will not simply stop when the specified value is reached, but when the Exponential Moving Average of the loss/accuracy is at least the target value or less/more (for loss/accuracy) for at least 200 batches. This is done to avoid stopping when some lucky batches is encountered.
stop_after_n_epochs = 50
stop_at_loss = false
stop_at_accuracy = false

[training.monitoring]
# If you want to log in neptune.ai, specify the project name. You need an account there + you need to have created a project with the correct name through their UI + You need to set up your API token: \nhttps://docs.neptune.ai/getting-started/installation. The API should be in an environmental variable called NEPTUNE_API_TOKEN.
# If everything is setup correctly, put your project name here, and you should get a lot of good logging for your training session'
neptune_proj_name = false


[saving_folders]
# The paths for saving the results and the model. If false, no saving will occur. Notice that, during training, the `train_id` will be appended to these folders. 
results_folder = 'results/decoder/'
model_output_folder = 'models/decoder'

[transformation]
# Fill color is the value used when performing transformations such as rotation. Will be ignored if no transformation is applied. 
fill_color = [0, 0, 0]

[transformation.values]
# Specifies the range for applying each transformation, allowing for detailed transformation augmentation. 
# For each transformation type (translation, scale, rotation), you can define a single range or multiple ranges.
# A single range is defined by a list with minimum and maximum values.
# Multiple ranges are defined by a list of lists, each specifying a different range.
# For example:
# - translation = [[-0.2, 0], [0.1, 0.5]] specifies two ranges for translation.
# - scale = [0.7, 1.3] specifies a single range for scale.

# You can be even more detailed with translation by specifying translation_X and translation_Y. 

# An uniform random variable is drawn for each parameter within the specified ranges.
# - Translation is expressed as a fraction of the image size for both horizontal and vertical translation.
# - Scale represents the scaling factor, where 1 keeps the image size unchanged.
# - Rotation is measured in degrees.
# Set any of these to "false" to disable the respective transformation.
translation_X = false
translation_Y = false
scale = false
rotation = false 

# Example usage:
# translation_X = [-0.2, 0.2]
# translation_Y = [-0.2, 0.2]
# scale = [0.7, 1.3]
# rotation = [0, 360]
